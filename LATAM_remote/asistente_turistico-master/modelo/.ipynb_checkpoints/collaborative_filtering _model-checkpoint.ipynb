{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('users_table.csv')\n",
    "ratings = pd.read_csv('users_ratings_table.csv')\n",
    "items = pd.read_csv('base_final_lugares.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings[ratings['rating']!='None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josel\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "ratings.loc[:, 'rating'] = ratings.loc[:, 'rating'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se usar columna de reviewer ya que user id es muy pesada\n",
    "n_users = users.reviewer_id.unique().shape[0]\n",
    "n_items = ratings.place_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear matriz de elementos de usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(ratings, values='rating', index=['reviewer_id'],\n",
    "                    columns=['place_id'], aggfunc=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = table.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular similutud del coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(data_matrix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacer predicciones basadas en las similitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type=='user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        \n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type=='item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prediction = predict(data_matrix, user_similarity, type='user')\n",
    "item_prediction = predict(data_matrix, item_similarity, type='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86185948, 0.86367306, 0.86456184, ..., 0.86731638, 0.86100663,\n",
       "        0.86651566],\n",
       "       [0.60374162, 0.62974484, 0.6284047 , ..., 0.63529782, 0.63104744,\n",
       "        0.61253486],\n",
       "       [0.71355034, 0.71215463, 0.71557001, ..., 0.71710585, 0.71388903,\n",
       "        0.71864901],\n",
       "       ...,\n",
       "       [0.72875393, 0.73379097, 0.7272502 , ..., 0.72563372, 0.72900475,\n",
       "        0.73467554],\n",
       "       [0.63920509, 0.64756895, 0.61726957, ..., 0.64886562, 0.63736887,\n",
       "        0.64402185],\n",
       "       [0.83304051, 0.83210362, 0.82648208, ..., 0.82748311, 0.807267  ,\n",
       "        0.82026265]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor de recomendaciones utilizando factorización de matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "\n",
    "  # Inicializando la matriz de ratings user-movie, no. de características latentes, alpha y beta.\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        \n",
    "    # Inicializando user-feature y movie-feature matrix \n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "        \n",
    "        # Inicializando los terminos bias \n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "        \n",
    "        # List of training samples\n",
    "        self.samples = [\n",
    "        (i, j, self.R[i, j])\n",
    "        for i in range(self.num_users)\n",
    "        for j in range(self.num_items)\n",
    "        if self.R[i, j] > 0\n",
    "        ]\n",
    "        \n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "        self.sgd()\n",
    "        mse = self.mse()\n",
    "        training_process.append((i, mse))\n",
    "        if (i+1) % 20 == 0:\n",
    "            print(\"Iteration: %d ; error = %.4f\" % (i+1, mse))\n",
    "\n",
    "        return training_process\n",
    "    \n",
    "    # Computing total mean squared error\n",
    "    def mse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(error)\n",
    "    \n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "            \n",
    "    # Ratings for user i and moive j\n",
    "    def get_rating(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    # Full user-movie rating matrix\n",
    "    def full_matrix(self):\n",
    "        return mf.b + mf.b_u[:,np.newaxis] + mf.b_i[np.newaxis:,] + mf.P.dot(mf.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100 ; error = 166.7259\n",
      "\n",
      "P x Q:\n",
      "[[4.60209848 4.58003542 4.58266375 ... 4.58115797 4.55518431 4.58200066]\n",
      " [4.61085851 4.58551757 4.59965225 ... 4.57731785 4.56635112 4.58701583]\n",
      " [4.61178664 4.58278715 4.59202618 ... 4.58805295 4.54720992 4.57832123]\n",
      " ...\n",
      " [4.60452328 4.56607337 4.56663106 ... 4.57400445 4.54011379 4.59218177]\n",
      " [4.61849226 4.59966058 4.58032301 ... 4.56230443 4.53378029 4.58050659]\n",
      " [4.58535637 4.57392836 4.58979775 ... 4.55175156 4.53438135 4.57758209]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mf = MF(data_matrix, K=20, alpha=0.001, beta=0.01, iterations=100)\n",
    "training_process = mf.train()\n",
    "print()\n",
    "print(\"P x Q:\")\n",
    "print(mf.full_matrix())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.57342063, 4.57159713, 4.57708222, 4.57126378, 4.58075804,\n",
       "       4.56867966, 4.5798508 , 4.5811524 , 4.5690783 , 4.57072207,\n",
       "       4.5786838 , 4.57961702, 4.57285577, 4.57332341, 4.5779751 ,\n",
       "       4.58146246, 4.57373582, 4.58315589, 4.57837839, 4.58055218,\n",
       "       4.57418298, 4.58152593, 4.57398011, 4.58078336, 4.57258953,\n",
       "       4.57588747, 4.57515964, 4.57338657, 4.56950239, 4.56324736,\n",
       "       4.57408551, 4.56749409, 4.56520319, 4.57008194, 4.57756093,\n",
       "       4.57053323, 4.57561234, 4.57375206, 4.57963488, 4.57387719,\n",
       "       4.57075838, 4.57031871, 4.57620751, 4.56971265, 4.56904515,\n",
       "       4.58340205, 4.58249334, 4.56809478, 4.57585153, 4.57092782,\n",
       "       4.56835521, 4.57539923, 4.57756355, 4.57856905, 4.57117001,\n",
       "       4.57180007, 4.57975516, 4.57712837, 4.58019791, 4.57610613,\n",
       "       4.58114804, 4.57215262, 4.56771252, 4.57261928, 4.5723324 ,\n",
       "       4.56540907, 4.57146975, 4.5663908 , 4.57422388, 4.57773931,\n",
       "       4.57320579, 4.57372473, 4.57962763, 4.57984771, 4.57187029,\n",
       "       4.57375416, 4.57540717, 4.58078345, 4.56826969, 4.58108075,\n",
       "       4.57559285, 4.56549952, 4.57560512, 4.57452624, 4.57687187,\n",
       "       4.57494439, 4.57269675, 4.57906871, 4.57244183, 4.57403988,\n",
       "       4.56708119, 4.57208217, 4.562787  , 4.57458956, 4.58372536,\n",
       "       4.57701024, 4.57588886, 4.57072531, 4.57912864, 4.57521704,\n",
       "       4.5813765 , 4.58159742, 4.57069152, 4.5793343 , 4.5791812 ,\n",
       "       4.57254258, 4.57507726, 4.5827496 , 4.57398908, 4.56476465,\n",
       "       4.58130191, 4.5810435 , 4.58331938, 4.57021767, 4.57391395,\n",
       "       4.57309579, 4.57587682, 4.56878291, 4.56631154, 4.56459839,\n",
       "       4.57570825, 4.56768835, 4.58059922, 4.57498019, 4.57319361,\n",
       "       4.5813129 , 4.56961076, 4.57270526, 4.57936864, 4.57321062,\n",
       "       4.57578109, 4.57477323, 4.57493439, 4.57428448, 4.5775735 ,\n",
       "       4.56345521, 4.57798457, 4.56932491, 4.575402  , 4.57971369,\n",
       "       4.57254151, 4.57918828, 4.56944873, 4.58566901, 4.57407599,\n",
       "       4.57933454, 4.57887458, 4.57364716, 4.5579235 , 4.57560078,\n",
       "       4.58231265, 4.57804603, 4.56453721, 4.56974195, 4.57334675,\n",
       "       4.57733763, 4.57806628, 4.58169502, 4.58003145, 4.57203955,\n",
       "       4.58383601, 4.56204296, 4.57739363, 4.57817856, 4.58445138,\n",
       "       4.57395168, 4.57888206, 4.57529918, 4.57977646, 4.57475882,\n",
       "       4.57094473, 4.5798479 , 4.57253043, 4.5783559 , 4.57901761,\n",
       "       4.58193127, 4.57027359, 4.57894748, 4.57028849, 4.56971108,\n",
       "       4.57184111, 4.56725352, 4.57557757, 4.57049931, 4.57543693,\n",
       "       4.5626936 , 4.57164589, 4.57823012, 4.57548965, 4.57817487,\n",
       "       4.56907941, 4.57365777, 4.57512857, 4.55854084, 4.57237777,\n",
       "       4.582195  , 4.5736435 , 4.55796132, 4.57376496, 4.57558625,\n",
       "       4.57420699, 4.57068782, 4.5746253 , 4.5791134 , 4.57123297,\n",
       "       4.56278377, 4.57947336, 4.5680801 , 4.57843073, 4.57718048,\n",
       "       4.57687534, 4.57131359, 4.57977839, 4.57198242, 4.57203796,\n",
       "       4.5705029 , 4.57574031, 4.58158064, 4.57517123, 4.58550144,\n",
       "       4.56642357, 4.56977754, 4.57793892, 4.57823143, 4.5680608 ,\n",
       "       4.5729896 , 4.57321357, 4.57882707, 4.57930352, 4.56458218,\n",
       "       4.56126903, 4.5710303 , 4.57350575, 4.58166138, 4.5829807 ,\n",
       "       4.57138441, 4.57772427, 4.57048237, 4.5754498 , 4.57966869,\n",
       "       4.57386531, 4.57042434, 4.57164081, 4.58531281, 4.57389017,\n",
       "       4.56824222, 4.57064629, 4.57767845, 4.57781064, 4.57093394,\n",
       "       4.57055044, 4.57895922, 4.57598465, 4.58038153, 4.57680966,\n",
       "       4.57336348, 4.58000984, 4.55998135, 4.57933613, 4.56345115,\n",
       "       4.57743682, 4.5802261 , 4.5684939 , 4.58411263, 4.58300408,\n",
       "       4.5726597 , 4.57573851, 4.58120156, 4.57506005, 4.57526681,\n",
       "       4.57639764, 4.56764089, 4.57107279, 4.57347585, 4.56567032,\n",
       "       4.57394243, 4.5674661 , 4.58073972, 4.57802188, 4.57680555,\n",
       "       4.58505958, 4.57477387, 4.57378392, 4.57830331, 4.56479195,\n",
       "       4.56946645, 4.57183972, 4.57397117, 4.57934477, 4.57520002,\n",
       "       4.5785088 , 4.58076726, 4.58048641, 4.5704897 , 4.57738577,\n",
       "       4.56890671, 4.57973588, 4.56820415, 4.57029499, 4.56805097,\n",
       "       4.5720883 , 4.57301151, 4.57647391, 4.57064783, 4.56833583,\n",
       "       4.58026833, 4.57805109, 4.57349555, 4.57483983, 4.57927824,\n",
       "       4.57901348, 4.57396115, 4.55926568, 4.57325147, 4.566184  ,\n",
       "       4.5755404 , 4.57975462, 4.5782216 , 4.57297851, 4.57325963,\n",
       "       4.57753134, 4.57976605, 4.57196638, 4.57568787, 4.57523196,\n",
       "       4.57094925, 4.57764354, 4.58266094, 4.57669831, 4.5751441 ,\n",
       "       4.56786814, 4.5748669 , 4.56827417, 4.55949244, 4.57513354,\n",
       "       4.57513703, 4.57392286, 4.5801546 , 4.57640415, 4.57982636,\n",
       "       4.56464532, 4.57351496, 4.57871148, 4.56942408, 4.57165312,\n",
       "       4.57001626, 4.57313696, 4.57152006, 4.57423243, 4.57117053,\n",
       "       4.57638446, 4.5803576 , 4.57202098, 4.56735361, 4.57452691,\n",
       "       4.5724032 , 4.57042836, 4.5786114 , 4.57349771, 4.57058771,\n",
       "       4.57525797, 4.5818155 , 4.56922328, 4.57831456, 4.5710097 ,\n",
       "       4.56147524, 4.581077  , 4.57483854, 4.57549026, 4.571196  ,\n",
       "       4.57030293, 4.56667288, 4.58165883, 4.57664395, 4.57034638,\n",
       "       4.56310607, 4.57202654, 4.56359061, 4.57314419, 4.57995178,\n",
       "       4.57902607, 4.56595555, 4.57685893, 4.57789329, 4.573725  ,\n",
       "       4.56547276, 4.57312228, 4.57651568, 4.5726303 , 4.57613779,\n",
       "       4.57270105, 4.57271173, 4.57863238, 4.57791541, 4.56830977,\n",
       "       4.57905372, 4.56821129, 4.56891782, 4.57247989, 4.57280001,\n",
       "       4.57934916, 4.58258844, 4.57862646, 4.56795596, 4.57584071,\n",
       "       4.58183006, 4.56958471, 4.56250695, 4.56766912, 4.57041019,\n",
       "       4.57836105, 4.57238925, 4.57601242, 4.57990612, 4.58105415,\n",
       "       4.5753012 , 4.57860584, 4.57538537, 4.58147052, 4.57994291,\n",
       "       4.57513659, 4.57729625, 4.5726444 , 4.5708804 , 4.57944172,\n",
       "       4.57131323, 4.57685178, 4.58171828, 4.57421848, 4.56628975,\n",
       "       4.57388041, 4.57612384, 4.57963659, 4.57860123, 4.5752926 ,\n",
       "       4.5771119 , 4.58230325, 4.57545174, 4.57679437, 4.57716908,\n",
       "       4.57050758, 4.58279181, 4.57673012, 4.56314598, 4.57726881,\n",
       "       4.56155657, 4.57435939, 4.58065689, 4.5709186 , 4.57646845,\n",
       "       4.56886366, 4.57044145, 4.5782017 , 4.57993656, 4.58412035,\n",
       "       4.57396731, 4.56971688, 4.57231194, 4.5726175 , 4.57642598,\n",
       "       4.5801441 , 4.57344638, 4.57146552, 4.57618448, 4.57254188,\n",
       "       4.57600768, 4.56659792, 4.57573726, 4.55904713, 4.57799375,\n",
       "       4.57276275, 4.56968197, 4.57702926, 4.58286962, 4.57478163,\n",
       "       4.56288914, 4.57922878, 4.56559321, 4.57454624, 4.58262119,\n",
       "       4.56975561, 4.57691261, 4.57324584, 4.56934303, 4.56608307,\n",
       "       4.57872255, 4.57870538, 4.56190104, 4.57276796, 4.58302404,\n",
       "       4.5797355 , 4.57066494, 4.57831116, 4.5776372 , 4.57301561,\n",
       "       4.57352321, 4.57746553, 4.57118867, 4.57578298, 4.57678197,\n",
       "       4.57403748, 4.57380139, 4.56851574, 4.57178667, 4.57751029,\n",
       "       4.57865039, 4.57048014, 4.57282796, 4.56758368, 4.56677537,\n",
       "       4.56512861, 4.57403284, 4.57473229, 4.57751565, 4.58164647,\n",
       "       4.56899376, 4.57398057, 4.5819146 , 4.57657988, 4.57589746,\n",
       "       4.57742976, 4.56495694, 4.57520559, 4.58208337, 4.57820775,\n",
       "       4.57891088, 4.57820363, 4.57632406, 4.57817516, 4.57647861,\n",
       "       4.56859227, 4.57960355, 4.57300334, 4.57754833, 4.56789956,\n",
       "       4.57167102, 4.57249213, 4.5804854 , 4.5722496 , 4.57444142,\n",
       "       4.56291072, 4.57817771, 4.57809193, 4.57225909, 4.57768392,\n",
       "       4.57642098, 4.57096026, 4.58233006, 4.56942978, 4.570404  ,\n",
       "       4.58232368, 4.58033591, 4.57569794, 4.57125949, 4.58311318,\n",
       "       4.58033324, 4.57732145, 4.57852231, 4.57172109, 4.57442376,\n",
       "       4.57856508, 4.56704907, 4.57153556, 4.57180942, 4.56639437,\n",
       "       4.56648388, 4.57504301, 4.57756638, 4.57010908, 4.57604099,\n",
       "       4.5773466 , 4.57234791, 4.56170328, 4.57280812, 4.56648276,\n",
       "       4.5782187 , 4.57963062, 4.56862244, 4.58190587, 4.5700112 ,\n",
       "       4.57283729, 4.57522872, 4.57880011, 4.58012143, 4.55852147,\n",
       "       4.56936779, 4.5799446 , 4.56903568, 4.56603024, 4.57434678,\n",
       "       4.5730112 , 4.58155915, 4.56782333, 4.57359819, 4.57628926,\n",
       "       4.57973652, 4.5787689 , 4.57714763, 4.57893455, 4.58189807,\n",
       "       4.57469514, 4.5783472 , 4.58062069, 4.56543177, 4.57944413,\n",
       "       4.58315447, 4.57483682, 4.5736374 , 4.58320814, 4.5705999 ,\n",
       "       4.56822617, 4.57236217, 4.57197802, 4.57393694, 4.57348123,\n",
       "       4.57906063, 4.57893651, 4.57425516, 4.57718812, 4.57122426,\n",
       "       4.57328271, 4.56844252, 4.57693528, 4.57404448, 4.57548089,\n",
       "       4.57715278, 4.56948089, 4.57665668, 4.57331569, 4.57513347,\n",
       "       4.57702225, 4.56872688, 4.57460481, 4.56699178, 4.56997274,\n",
       "       4.57344509, 4.57558964, 4.58173486, 4.57489467, 4.57119088,\n",
       "       4.57011957, 4.57329877, 4.57427826, 4.57690768, 4.57390181,\n",
       "       4.57716731, 4.56385426, 4.58076804, 4.57535988, 4.57687727,\n",
       "       4.56222467, 4.57208452, 4.5764114 , 4.56302268, 4.57852299,\n",
       "       4.57303219, 4.57762163, 4.57163126, 4.58456737, 4.57849157,\n",
       "       4.56163395, 4.56755829, 4.58049561, 4.56985876, 4.57766351,\n",
       "       4.56889678, 4.57689716, 4.57458707, 4.57324618, 4.57557521,\n",
       "       4.57993756, 4.58584099, 4.57322357, 4.5707985 , 4.57503248,\n",
       "       4.57531627, 4.57863909, 4.57924497, 4.58138627, 4.57072474,\n",
       "       4.56797708, 4.58035534, 4.57233329, 4.57538108, 4.57406534,\n",
       "       4.57372464, 4.57221522, 4.58035166, 4.56622673, 4.57727722,\n",
       "       4.56177844, 4.57433897, 4.56979421, 4.57922532, 4.57751073,\n",
       "       4.56858733, 4.57364236, 4.57650627, 4.5767356 , 4.57965881,\n",
       "       4.57115863, 4.5839894 , 4.56490614, 4.57499356, 4.57725418,\n",
       "       4.57398098, 4.5744344 , 4.57820302, 4.57304127, 4.57754608,\n",
       "       4.57987533, 4.58136406, 4.57911258, 4.5772211 , 4.57592884,\n",
       "       4.58114998, 4.57667456, 4.5728155 , 4.58460649, 4.56846032,\n",
       "       4.57699362, 4.57332573, 4.57633007, 4.57257497, 4.57065442,\n",
       "       4.5807641 , 4.57386992, 4.56798727, 4.57221585, 4.56243131,\n",
       "       4.57527509, 4.56340132, 4.57248598, 4.56385532, 4.57521734,\n",
       "       4.57248419, 4.57250697, 4.58013624, 4.57453455, 4.57287789,\n",
       "       4.57255606, 4.58189991, 4.56909199, 4.57934713, 4.57914527,\n",
       "       4.57235332, 4.57509222, 4.58336487, 4.57067163, 4.57864786,\n",
       "       4.57225561, 4.57281399, 4.57097508, 4.57132765, 4.57715986,\n",
       "       4.57539624, 4.57266845, 4.56888374, 4.56401328, 4.57976077,\n",
       "       4.56918499, 4.56905395, 4.57227356, 4.56442925, 4.57258533,\n",
       "       4.57549315, 4.57485762, 4.57203731, 4.57314182, 4.57117915,\n",
       "       4.57213837, 4.57429567, 4.57224135, 4.57425998, 4.57972719,\n",
       "       4.57178588, 4.57241329, 4.57538064, 4.57211131, 4.57495492,\n",
       "       4.57851593, 4.57875494, 4.57910608, 4.57722693, 4.5676333 ,\n",
       "       4.57389605, 4.5770053 , 4.5758406 , 4.57585319, 4.57161763,\n",
       "       4.57012752, 4.56336141, 4.57314918, 4.56729802, 4.57651154,\n",
       "       4.56869766, 4.58100761, 4.57710678, 4.56855828, 4.57992969,\n",
       "       4.57538988, 4.57319647, 4.57587954, 4.56240575, 4.58737679,\n",
       "       4.57140267, 4.56733971, 4.57948285, 4.56929145, 4.56986678,\n",
       "       4.57590239, 4.57276607, 4.57443233, 4.57333429, 4.58023228,\n",
       "       4.56681011, 4.56768916, 4.57115245, 4.57338536, 4.57804106,\n",
       "       4.57804147, 4.57888836, 4.57713372, 4.57425059, 4.57350294,\n",
       "       4.58477894, 4.56986954, 4.57136221, 4.57039785, 4.58119326,\n",
       "       4.57693658, 4.56942671, 4.56160725, 4.57151262, 4.57762223,\n",
       "       4.57512618, 4.5801306 , 4.56917145, 4.5688571 , 4.57483829,\n",
       "       4.57530905, 4.57385443, 4.56915606, 4.57490101, 4.5694555 ,\n",
       "       4.57868276, 4.57581458, 4.5725299 , 4.5757992 , 4.58163009,\n",
       "       4.57848143, 4.57018627, 4.57184363, 4.5716975 , 4.57606008,\n",
       "       4.5773144 , 4.56891048, 4.57068349, 4.5721043 , 4.57697361,\n",
       "       4.57849772, 4.57909961, 4.56941007, 4.57795414, 4.56245137,\n",
       "       4.58260828, 4.57735787, 4.56886052, 4.57025156, 4.57085647,\n",
       "       4.56948445, 4.57979783, 4.5773185 , 4.57855942, 4.56967064,\n",
       "       4.56806024, 4.57229103, 4.57705462, 4.57144441, 4.58030785,\n",
       "       4.57031586, 4.57804978, 4.57944223, 4.57612282, 4.57480634,\n",
       "       4.57508353, 4.57677527, 4.58156654, 4.5635786 , 4.57409873,\n",
       "       4.57844626, 4.57190763, 4.57419521, 4.57248256, 4.57278205,\n",
       "       4.57855674, 4.57528541, 4.57483177, 4.57446481, 4.57450323,\n",
       "       4.57951199, 4.57185353, 4.57477291, 4.57803762, 4.58089222,\n",
       "       4.57142651, 4.5684821 , 4.57467297, 4.57473405, 4.58114538,\n",
       "       4.57709783, 4.57457293, 4.57130709, 4.57286035, 4.57322962,\n",
       "       4.5814198 , 4.57197639, 4.57442595, 4.57418571, 4.57363206,\n",
       "       4.57268758, 4.57920725, 4.57733828, 4.57375352, 4.58370847,\n",
       "       4.57238443, 4.58080367, 4.57473832, 4.5752175 , 4.57680981,\n",
       "       4.57657726, 4.567736  , 4.57878722, 4.56670561, 4.57200527,\n",
       "       4.58132684, 4.57567358, 4.57755375, 4.56625734, 4.56914492,\n",
       "       4.57406776, 4.5716189 , 4.57048051, 4.58350773, 4.57186822,\n",
       "       4.57862022, 4.57606981, 4.57332807, 4.58122094, 4.57821176,\n",
       "       4.58278333, 4.57659705, 4.57272547, 4.57037735, 4.57753743,\n",
       "       4.56406098, 4.57215149, 4.57328381, 4.57202578, 4.58053863,\n",
       "       4.57721398, 4.57525705, 4.56939178, 4.56943601, 4.57455414,\n",
       "       4.57510219, 4.58191799, 4.57898275, 4.57674109, 4.56865937,\n",
       "       4.56686781, 4.57458308, 4.568912  , 4.56319223, 4.57575938,\n",
       "       4.56778923, 4.5725444 , 4.57553582, 4.57442162, 4.57277376,\n",
       "       4.57690741, 4.5791814 , 4.58592168, 4.58418866, 4.56946908,\n",
       "       4.56845717, 4.57280264, 4.56786368, 4.58571179, 4.58351546,\n",
       "       4.57849628, 4.57615698, 4.56864293, 4.57176265, 4.57201253,\n",
       "       4.57843959, 4.57682491, 4.56681645, 4.57157544, 4.56404672])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.full_matrix().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
