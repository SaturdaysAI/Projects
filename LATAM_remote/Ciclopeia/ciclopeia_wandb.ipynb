{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ciclopeia_wandb.ipynb",
      "provenance": [],
      "mount_file_id": "1xw2_Yi7CpEEa5UbN0547aL_a9vcpop0U",
      "authorship_tag": "ABX9TyPMo6qMAXnSqnHWapeO0U5H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/digicornio/ciclopeia/blob/main/ciclopeia_wandb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Install requirements"
      ],
      "metadata": {
        "id": "klMY6a2wksnG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Cispdq9dDPa"
      },
      "outputs": [],
      "source": [
        "# clone and install yolov5\n",
        "%%capture\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd /content/yolov5\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# install wandb for training metrics\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import core and utilities libraries\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import Image, clear_output \n",
        "\n",
        "# import ai and training metric libraries\n",
        "import torch\n",
        "from yolov5 import utils\n",
        "\n",
        "# validate CUDA is enabled\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UptYw3zfdEIR",
        "outputId": "04b5fdd3-9cbb-48f3-9c86-7164595d0ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v6.0-244-g9cf80b7 torch 1.10.0+cu111 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 43.2/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Dataset preparation"
      ],
      "metadata": {
        "id": "BE5YZ-ujk5EO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define dataset source and target after split\n",
        "dataset_source = '/content/drive/MyDrive/Saturdays_AI/RED/DEMODAY_PROJECT/nuevo-dataset/' # change to your path \n",
        "dataset_target = '/content/yolov5/custom_dataset/'"
      ],
      "metadata": {
        "id": "iGtYr6frdxHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list and compar images against labels\n",
        "labels = [os.path.join(dataset_source, x) for x in os.listdir(dataset_source) if x[-3:] == \"txt\"]\n",
        "images = [os.path.join(dataset_source, x) for x in os.listdir(dataset_source) if x[-3:] == \"jpg\"]\n",
        "print(f'| Total: {len(labels)} labels & {len(images)} images from: {dataset_source}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsOZmI2Krsao",
        "outputId": "5dfd1418-8e52-4ca1-db4a-2043a51a8618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Total: 1045 labels & 1045 images from: /content/drive/MyDrive/Saturdays_AI/RED/DEMODAY_PROJECT/nuevo-dataset/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to copy images and labels from source (gdrive) to target (colab)\n",
        "def copy_files_to_folder(list_of_files, destination_folder):\n",
        "    for f in list_of_files:\n",
        "        try:\n",
        "            shutil.copy(f, destination_folder)\n",
        "        except:\n",
        "            print(f)\n",
        "            assert False   "
      ],
      "metadata": {
        "id": "3UIMbV0ZgLZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# training, validation & test splits\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size = 0.2, random_state = 1)\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(val_images, val_labels, test_size = 0.5, random_state = 1)"
      ],
      "metadata": {
        "id": "2gdCb2mKgfgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creates dataset_target folders to copy images and labeles from dataset source\n",
        "# !mkdir /content/yolov5/custom_dataset custom_dataset/train custom_dataset/val custom_dataset/test\n",
        "!mkdir {dataset_target} {dataset_target + 'train'} {dataset_target + 'val'} {dataset_target + 'test'} "
      ],
      "metadata": {
        "id": "R-qEng_Eg-oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy images and labels into dataset_target folders\n",
        "copy_files_to_folder(train_images + train_labels, dataset_target + 'train')\n",
        "copy_files_to_folder(val_images + val_labels, dataset_target + 'val')\n",
        "copy_files_to_folder(test_images + test_labels, dataset_target + 'test')"
      ],
      "metadata": {
        "id": "2vqc_fFggiqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Train YOLOv5 model"
      ],
      "metadata": {
        "id": "lzZRBSqglDOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "# login into wandb\n",
        "wandb.login()\n",
        "# configure wandb project and user\n",
        "wandb.init(project=\"ciclopeiav20\", entity=\"digicornio\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "xU2KV0aObvk0",
        "outputId": "d56f79dd-0477-40ee-89b2-ae4580fc04c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdigicornio\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/digicornio/ciclopeiav20/runs/2nreezvb\" target=\"_blank\">rare-disco-2</a></strong> to <a href=\"https://wandb.ai/digicornio/ciclopeiav20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f4ad241ad50>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/digicornio/ciclopeiav20/runs/2nreezvb?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import yaml\n",
        "# creates .yaml to define clases and dataset locations\n",
        "data={\n",
        "\n",
        "    'names':['$1USD', '$2USD', '$5USD', '$10USD', '$20USD', '$50USD', '$100USD'],\n",
        "    'nc': 7,\n",
        "    'train': \"custom_dataset/train\",\n",
        "    'val': \"custom_dataset/val\",\n",
        " \n",
        "    # 'depth_multiple': 0.33,\n",
        "    # 'width_multiple': 0.50,\n",
        "\n",
        "    # 'anchors':\n",
        "    # - [10,13, 16,30, 33,23] \n",
        "    # - [30,61, 62,45, 59,119]\n",
        "    # - [116,90, 156,198, 373,326] \n",
        "\n",
        "    # 'backbone':\n",
        "    # [[-1, 1, Focus, [64, 3]],\n",
        "    # [-1, 1, Conv, [128, 3, 2]],\n",
        "    # [-1, 3, Bottleneck, [128]],\n",
        "    # [-1, 1, Conv, [256, 3, 2]],\n",
        "    # [-1, 9, BottleneckCSP, [256]],\n",
        "    # [-1, 1, Conv, [512, 3, 2]], \n",
        "    # [-1, 9, BottleneckCSP, [512]],\n",
        "    # [-1, 1, Conv, [1024, 3, 2]],\n",
        "    # [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "    # [-1, 6, BottleneckCSP, [1024]],\n",
        "    # ]\n",
        "\n",
        "    # 'head':\n",
        "    # [[-1, 3, BottleneckCSP, [1024, False]],\n",
        "    # [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1, 0]],\n",
        "    # [-2, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
        "    # [[-1, 6], 1, Concat, [1]],\n",
        "    # [-1, 1, Conv, [512, 1, 1]],\n",
        "    # [-1, 3, BottleneckCSP, [512, False]],\n",
        "    # [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1, 0]],\n",
        "    # [-2, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
        "    # [[-1, 4], 1, Concat, [1]],\n",
        "    # [-1, 1, Conv, [256, 1, 1]],\n",
        "    # [-1, 3, BottleneckCSP, [256, False]],\n",
        "    # [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1, 0]],\n",
        "\n",
        "    # [[], 1, Detect, [nc, anchors]],\n",
        "    # ]\n",
        "\n",
        " }\n",
        "with open('data/usd_bills.yaml', 'w') as outfile:\n",
        "    yaml.dump(data, outfile)"
      ],
      "metadata": {
        "id": "Sbtvuf1XzxBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python utils/loggers/wandb/log_dataset.py --project ciclopeia --data data/usd_bills.yaml"
      ],
      "metadata": {
        "id": "vRhJY7_44dd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W37M7-lB-JBa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e90fe526-7dfc-4940-eae4-541581d69432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdigicornio\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data/usd_bills.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=ciclopeia, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=1, local_rank=-1, entity=None, upload_dataset=True, bbox_interval=1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "YOLOv5 üöÄ v6.0-244-g9cf80b7 torch 1.10.0+cu111 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ciclopeia', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfeasible-dream-10\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/digicornio/ciclopeia\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/digicornio/ciclopeia/runs/xxcm9wwa\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/yolov5/wandb/run-20220210_031632-xxcm9wwa\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Scanning '/content/yolov5/custom_dataset/train' images and labels...664 found, 171 missing, 47 empty, 1 corrupt: 100% 836/836 [00:00<00:00, 1475.97it/s]\n",
            "WARNING: /content/yolov5/custom_dataset/train/001-00001642884132.jpg: ignoring corrupt image/label: invalid image format GIF\n",
            "New cache created: /content/yolov5/custom_dataset/train.cache\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/yolov5/custom_dataset/train)... Done. 2.5s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/yolov5/custom_dataset/train)... Done. 0.8s\n",
            "100% 1/1 [00:03<00:00,  3.37s/it]\n",
            "100% 835/835 [01:01<00:00, 13.63it/s]\n",
            "Scanning '/content/yolov5/custom_dataset/val' images and labels...7 found, 97 missing, 1 empty, 0 corrupt: 100% 104/104 [00:00<00:00, 1997.53it/s]\n",
            "New cache created: /content/yolov5/custom_dataset/val.cache\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/yolov5/custom_dataset/val)... Done. 0.3s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/yolov5/custom_dataset/val)... Done. 0.2s\n",
            "100% 1/1 [00:00<00:00,  1.95it/s]\n",
            "100% 104/104 [00:09<00:00, 11.24it/s]\n",
            "Created dataset config file data/usd_bills_wandb.yaml\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact val:v2, 117.26MB. 418 files... Done. 0:0:0\n",
            "Mapping dataset\n",
            "100% 104/104 [00:00<00:00, 712757.54it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact val:v2, 117.26MB. 418 files... Done. 0:0:0\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.0M/14.0M [00:00<00:00, 34.1MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [7, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 270 layers, 7038508 parameters, 7038508 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5/custom_dataset/train.cache' images and labels... 664 found, 171 missing, 47 empty, 1 corrupt: 100% 836/836 [00:00<?, ?it/s]\n",
            "WARNING: /content/yolov5/custom_dataset/train/001-00001642884132.jpg: ignoring corrupt image/label: invalid image format GIF\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/custom_dataset/val.cache' images and labels... 7 found, 97 missing, 1 empty, 0 corrupt: 100% 104/104 [00:00<?, ?it/s]\n",
            "Plotting labels to ciclopeia/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.78 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mciclopeia/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "  0% 0/53 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G    0.1092   0.03181   0.06099        44       640:   2% 1/53 [00:30<26:10, 30.20s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G    0.1049   0.03124   0.06172        39       640:   4% 2/53 [00:54<22:42, 26.71s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G   0.09405   0.03123    0.0538        39       640:   6% 3/53 [01:18<21:13, 25.48s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G    0.1001   0.03038   0.05668        29       640:   8% 4/53 [01:43<20:32, 25.16s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G    0.1046   0.03009   0.05638        32       640:   9% 5/53 [02:06<19:41, 24.60s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G   0.09942    0.0301   0.05327        43       640:  11% 6/53 [02:30<18:58, 24.22s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G   0.09538   0.02951   0.05107        25       640:  13% 7/53 [02:53<18:22, 23.96s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G   0.09235   0.02946   0.04955        37       640:  15% 8/53 [03:16<17:48, 23.74s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G   0.09506   0.02924    0.0504        32       640:  17% 9/53 [03:40<17:20, 23.66s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G   0.09325   0.02909   0.04914        33       640:  19% 10/53 [04:03<16:51, 23.51s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G   0.09399   0.02908    0.0505        37       640:  21% 11/53 [04:27<16:30, 23.57s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G   0.09533   0.02887   0.05135        35       640:  23% 12/53 [04:50<16:01, 23.45s/it]/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "       0/9        0G   0.09533   0.02887   0.05135        35       640:  23% 12/53 [04:58<16:59, 24.87s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 642, in <module>\n",
            "    main(opt)\n",
            "  File \"train.py\", line 538, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"train.py\", line 329, in train\n",
            "    pred = model(imgs)  # forward\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/yolov5/models/yolo.py\", line 126, in forward\n",
            "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
            "  File \"/content/yolov5/models/yolo.py\", line 149, in _forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/yolov5/models/common.py\", line 139, in forward\n",
            "    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 141, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/yolov5/models/common.py\", line 105, in forward\n",
            "    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/yolov5/models/common.py\", line 47, in forward\n",
            "    return self.act(self.bn(self.conv(x)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\", line 384, in forward\n",
            "    return F.silu(input, inplace=self.inplace)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1898, in silu\n",
            "    return torch._C._nn.silu_(input)\n",
            "KeyboardInterrupt\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n",
            "/usr/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown\n",
            "  len(cache))\n",
            "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f4ad2f40890>> (for post_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
          ]
        }
      ],
      "source": [
        "!python train.py \\\n",
        "  --img 640 \\\n",
        "  --batch 16 \\\n",
        "  --epochs 10 \\\n",
        "  --data data/usd_bills.yaml \\\n",
        "  --project ciclopeia \\\n",
        "  --upload_dataset \\\n",
        "  --bbox_interval 1 \\\n",
        "  --save-period 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Evaluate YOLOv5 model performance\n"
      ],
      "metadata": {
        "id": "DbX-lUN7pWLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 416 --conf 0.1 --source {dataset.location}/test/images"
      ],
      "metadata": {
        "id": "UurhOHBpCVeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "bRTWq8rPwb-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export your model's weights for future use\n",
        "from google.colab import files\n",
        "files.download('./runs/train/exp/weights/best.pt')"
      ],
      "metadata": {
        "id": "w56QG1BDwlrZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}