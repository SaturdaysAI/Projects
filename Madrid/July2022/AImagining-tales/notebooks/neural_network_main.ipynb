{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"saturdays-cuentos-main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"metadata":{"id":"26rEzsMcFUE7","executionInfo":{"status":"ok","timestamp":1654700147107,"user_tz":-120,"elapsed":594,"user":{"displayName":"Alejandra De Francisco","userId":"05512330351082878412"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import IPython\n","js_code = '''\n","function ClickConnect(){\n","console.log(\"Working\");\n","document.querySelector(\"colab-toolbar-button#connect\").click()\n","}\n","setInterval(ClickConnect,60000)\n","'''\n","display(IPython.display.Javascript(js_code))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"H8mqvPoPZMz-","executionInfo":{"status":"ok","timestamp":1654700147108,"user_tz":-120,"elapsed":9,"user":{"displayName":"Alejandra De Francisco","userId":"05512330351082878412"}},"outputId":"72ef6dcc-9147-4aa7-cdb5-6ad3280d6699"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","function ClickConnect(){\n","console.log(\"Working\");\n","document.querySelector(\"colab-toolbar-button#connect\").click()\n","}\n","setInterval(ClickConnect,60000)\n"]},"metadata":{}}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ng0GYzb_F-CE","executionInfo":{"status":"ok","timestamp":1654700174686,"user_tz":-120,"elapsed":27585,"user":{"displayName":"Alejandra De Francisco","userId":"05512330351082878412"}},"outputId":"3cbd0bce-51d5-455e-dcdf-83cd3ff1ad2e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yes3EwkoQOtn","executionInfo":{"status":"ok","timestamp":1654700174687,"user_tz":-120,"elapsed":11,"user":{"displayName":"Alejandra De Francisco","userId":"05512330351082878412"}},"outputId":"07bbaf8f-03fa-4c54-9732-ad9601f51a10"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["%cd drive/MyDrive/CURSO/Proyecto/saturdays-cuentos-code/"],"metadata":{"id":"cV_fULHGGlMp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654700175556,"user_tz":-120,"elapsed":874,"user":{"displayName":"Alejandra De Francisco","userId":"05512330351082878412"}},"outputId":"861064b3-3855-475a-f0a3-e421cc498e96"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CURSO/Proyecto/saturdays-cuentos-code\n"]}]},{"cell_type":"code","source":["#@markdown #**Installation of libraries**\n","# @markdown This cell will take a little while because it has to download several libraries\n","\n","#@markdown ---\n"," \n","print(\"Installing CLIP...\")\n","!git clone https://github.com/openai/CLIP                 &> /dev/null\n"," \n","print(\"Installing Python Libraries for AI...\")\n","!git clone https://github.com/CompVis/taming-transformers &> /dev/null\n","!pip install transformers                                 &> /dev/null\n","!pip install ftfy regex tqdm omegaconf pytorch-lightning  &> /dev/null\n","!pip install kornia                                       &> /dev/null\n","!pip install einops                                       &> /dev/null\n","!pip install wget                                         &> /dev/null\n"," \n","print(\"Installing libraries for metadata management...\")\n","!pip install stegano                                      &> /dev/null\n","!apt install exempi                                       &> /dev/null\n","!pip install python-xmp-toolkit                           &> /dev/null\n","!pip install imgtag                                       &> /dev/null\n","!pip install pillow==7.1.2                                &> /dev/null\n"," \n","print(\"Installing Python libraries for creating videos...\")\n","!pip install imageio-ffmpeg                               &> /dev/null\n","!mkdir steps\n","!pip install fpdf\n","print(\"Installation completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"3tZur5uwa_fK","executionInfo":{"status":"ok","timestamp":1654700254425,"user_tz":-120,"elapsed":63669,"user":{"displayName":"Alejandra De Francisco","userId":"05512330351082878412"}},"outputId":"1f21f032-78aa-44a5-f451-fa273d3f0304"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing CLIP...\n","Installing Python Libraries for AI...\n","Installing libraries for metadata management...\n","Installing Python libraries for creating videos...\n","mkdir: cannot create directory ‘steps’: File exists\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fpdf\n","  Downloading fpdf-1.7.2.tar.gz (39 kB)\n","Building wheels for collected packages: fpdf\n","  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40725 sha256=20f6793c732a63268c5292698dcfde341aa3bf0bdd79648191893ae956d4b627\n","  Stored in directory: /root/.cache/pip/wheels/d7/ca/c8/86467e7957bbbcbdf4cf4870fc7dc95e9a16404b2e3c3a98c3\n","Successfully built fpdf\n","Installing collected packages: fpdf\n","Successfully installed fpdf-1.7.2\n","Installation completed.\n"]}]},{"cell_type":"code","source":["!python main_tales.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqwkoID9Sg1z","executionInfo":{"status":"ok","timestamp":1654707391898,"user_tz":-120,"elapsed":1447152,"user":{"displayName":"Alejandra De Francisco","userId":"05512330351082878412"}},"outputId":"bbbb384a-02ab-40df-9ddf-0bed41122c38"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading CSV to generate json config file\n","beauty-and-beast-method2-short.csv\n","   Unnamed: 0  ... text_size\n","0           0  ...        40\n","1           1  ...        12\n","2           2  ...        12\n","3           3  ...        12\n","4           4  ...        12\n","5           5  ...        12\n","6           6  ...        12\n","\n","[7 rows x 5 columns]\n","Download model...\n","Getting parameters for NN...\n","Generating image 0\n","Launching AI...\n","Using device: cuda:0\n","Using texts: ['The Story of Beauty and the Beast', 'watercolor']\n","Using seed: 8110762317699524981\n","Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n","loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n","VQLPIPSWithDiscriminator running with hinge loss.\n","Restored from vqgan_imagenet_f16_16384.ckpt\n","0it [00:00, ?it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","i: 0, loss: 1.9107, losses: 0.956558, 0.95414\n","<IPython.core.display.Image object>\n","i: 50, loss: 1.62021, losses: 0.830516, 0.789699\n","<IPython.core.display.Image object>\n","i: 100, loss: 1.54987, losses: 0.778339, 0.77153\n","<IPython.core.display.Image object>\n","i: 150, loss: 1.51009, losses: 0.738887, 0.771201\n","<IPython.core.display.Image object>\n","i: 200, loss: 1.49605, losses: 0.730137, 0.765913\n","<IPython.core.display.Image object>\n","i: 250, loss: 1.48743, losses: 0.718805, 0.768625\n","<IPython.core.display.Image object>\n","i: 300, loss: 1.49029, losses: 0.721691, 0.768601\n","<IPython.core.display.Image object>\n","Getting generated image...\n","Saving generated image to results folder...\n","Getting parameters for NN...\n","Generating image 1\n","Launching AI...\n","Using device: cuda:0\n","Using texts: ['after a sudden storm the merchant found a castle where he found magnificent rooms and delicious food .', 'watercolor']\n","Using seed: 67762961108494253\n","Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n","loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n","VQLPIPSWithDiscriminator running with hinge loss.\n","Restored from vqgan_imagenet_f16_16384.ckpt\n","0it [00:00, ?it/s]\n","i: 0, loss: 1.88904, losses: 0.939947, 0.949098\n","<IPython.core.display.Image object>\n","i: 50, loss: 1.59795, losses: 0.787771, 0.810175\n","<IPython.core.display.Image object>\n","i: 100, loss: 1.51202, losses: 0.734358, 0.777662\n","<IPython.core.display.Image object>\n","i: 150, loss: 1.4962, losses: 0.725319, 0.77088\n","<IPython.core.display.Image object>\n","i: 200, loss: 1.47623, losses: 0.714096, 0.762136\n","<IPython.core.display.Image object>\n","i: 250, loss: 1.49003, losses: 0.720396, 0.769632\n","<IPython.core.display.Image object>\n","i: 300, loss: 1.48256, losses: 0.717381, 0.765175\n","<IPython.core.display.Image object>\n","Getting generated image...\n","Saving generated image to results folder...\n","Getting parameters for NN...\n","Generating image 2\n","Launching AI...\n","Using device: cuda:0\n","Using texts: ['the merchant fell on his knees before the Beast . he promised to bring her back a rose from his journey . Beauty was led to the castle by the merchant.', 'watercolor']\n","Using seed: 3099221218785835875\n","Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n","loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n","VQLPIPSWithDiscriminator running with hinge loss.\n","Restored from vqgan_imagenet_f16_16384.ckpt\n","0it [00:00, ?it/s]\n","i: 0, loss: 1.90539, losses: 0.952153, 0.953239\n","<IPython.core.display.Image object>\n","i: 50, loss: 1.60857, losses: 0.815834, 0.792739\n","<IPython.core.display.Image object>\n","i: 100, loss: 1.50983, losses: 0.729368, 0.780463\n","<IPython.core.display.Image object>\n","i: 150, loss: 1.4659, losses: 0.694766, 0.771135\n","<IPython.core.display.Image object>\n","i: 200, loss: 1.4522, losses: 0.686078, 0.766119\n","<IPython.core.display.Image object>\n","i: 250, loss: 1.44227, losses: 0.678901, 0.76337\n","<IPython.core.display.Image object>\n","i: 300, loss: 1.44345, losses: 0.685462, 0.757984\n","<IPython.core.display.Image object>\n","Getting generated image...\n","Saving generated image to results folder...\n","Getting parameters for NN...\n","Generating image 3\n","Launching AI...\n","Using device: cuda:0\n","Using texts: ['Beauty was frightened of the Beast, and shuddered at the sight of it . Beauty was amazed to discover that she was actually enjoying its conversation .', 'watercolor']\n","Using seed: 17708339643723469509\n","Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n","loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n","VQLPIPSWithDiscriminator running with hinge loss.\n","Restored from vqgan_imagenet_f16_16384.ckpt\n","0it [00:00, ?it/s]\n","i: 0, loss: 1.92517, losses: 0.955653, 0.969518\n","<IPython.core.display.Image object>\n","i: 50, loss: 1.64439, losses: 0.853994, 0.790397\n","<IPython.core.display.Image object>\n","i: 100, loss: 1.57672, losses: 0.795996, 0.78072\n","<IPython.core.display.Image object>\n","i: 150, loss: 1.5479, losses: 0.78315, 0.764754\n","<IPython.core.display.Image object>\n","i: 200, loss: 1.53676, losses: 0.772602, 0.764159\n","<IPython.core.display.Image object>\n","i: 250, loss: 1.52923, losses: 0.768891, 0.760336\n","<IPython.core.display.Image object>\n","i: 300, loss: 1.53093, losses: 0.772633, 0.758294\n","<IPython.core.display.Image object>\n","Getting generated image...\n","Saving generated image to results folder...\n","Getting parameters for NN...\n","Generating image 4\n","Launching AI...\n","Using device: cuda:0\n","Using texts: ['Beauty threw herself at the Beast\\'s feet in delight . How kind you are! \"', 'watercolor']\n","Using seed: 16347822887700082264\n","Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n","loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n","VQLPIPSWithDiscriminator running with hinge loss.\n","Restored from vqgan_imagenet_f16_16384.ckpt\n","0it [00:00, ?it/s]\n","i: 0, loss: 1.94733, losses: 0.979491, 0.96784\n","<IPython.core.display.Image object>\n","i: 50, loss: 1.61831, losses: 0.829625, 0.788683\n","<IPython.core.display.Image object>\n","i: 100, loss: 1.54617, losses: 0.773318, 0.772856\n","<IPython.core.display.Image object>\n","i: 150, loss: 1.52838, losses: 0.763523, 0.764854\n","<IPython.core.display.Image object>\n","i: 200, loss: 1.5149, losses: 0.762324, 0.752571\n","<IPython.core.display.Image object>\n","i: 250, loss: 1.50684, losses: 0.749034, 0.757806\n","<IPython.core.display.Image object>\n","i: 300, loss: 1.49763, losses: 0.749365, 0.748265\n","<IPython.core.display.Image object>\n","Getting generated image...\n","Saving generated image to results folder...\n","Getting parameters for NN...\n","Generating image 5\n","Launching AI...\n","Using device: cuda:0\n","Using texts: ['the Beast\\'s ugly face turned into the face of a handsome young man . \"I was suffering in silence, and couldn\\'t tell my frightful secret,', 'watercolor']\n","Using seed: 13926966777190089000\n","Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n","loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n","VQLPIPSWithDiscriminator running with hinge loss.\n","Restored from vqgan_imagenet_f16_16384.ckpt\n","0it [00:00, ?it/s]\n","i: 0, loss: 1.91326, losses: 0.946521, 0.966739\n","<IPython.core.display.Image object>\n","i: 50, loss: 1.63127, losses: 0.833295, 0.797976\n","<IPython.core.display.Image object>\n","i: 100, loss: 1.57236, losses: 0.814384, 0.75798\n","<IPython.core.display.Image object>\n","i: 150, loss: 1.55358, losses: 0.804664, 0.748911\n","<IPython.core.display.Image object>\n","i: 200, loss: 1.5447, losses: 0.79634, 0.748364\n","<IPython.core.display.Image object>\n","i: 250, loss: 1.54276, losses: 0.799268, 0.743491\n","<IPython.core.display.Image object>\n","i: 300, loss: 1.53278, losses: 0.791559, 0.741217\n","<IPython.core.display.Image object>\n","Getting generated image...\n","Saving generated image to results folder...\n","Getting parameters for NN...\n","Generating image 6\n","Launching AI...\n","Using device: cuda:0\n","Using texts: ['the wedding took place shortly after and the young Prince would have nothing but roses in his gardens . the castle is known as the Castle of the Rose.', 'watercolor']\n","Using seed: 8248914154841983542\n","Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n","loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n","VQLPIPSWithDiscriminator running with hinge loss.\n","Restored from vqgan_imagenet_f16_16384.ckpt\n","0it [00:00, ?it/s]\n","i: 0, loss: 1.90634, losses: 0.947351, 0.958984\n","<IPython.core.display.Image object>\n","i: 50, loss: 1.62876, losses: 0.845139, 0.783625\n","<IPython.core.display.Image object>\n","i: 100, loss: 1.58946, losses: 0.822789, 0.766673\n","<IPython.core.display.Image object>\n","i: 150, loss: 1.56529, losses: 0.78827, 0.777024\n","<IPython.core.display.Image object>\n","i: 200, loss: 1.52032, losses: 0.7421, 0.778221\n","<IPython.core.display.Image object>\n","i: 250, loss: 1.49544, losses: 0.720128, 0.775309\n","<IPython.core.display.Image object>\n","i: 300, loss: 1.47664, losses: 0.711912, 0.764732\n","<IPython.core.display.Image object>\n","Getting generated image...\n","Saving generated image to results folder...\n","---------------------------------------------------------------------------\n","Building PDF....\n","Generating page 0\n","Building page...\n","Generating page 1\n","Building page...\n","Generating page 2\n","Building page...\n","Generating page 3\n","Building page...\n","Generating page 4\n","Building page...\n","Generating page 5\n","Building page...\n","Generating page 6\n","Building page...\n","DONE\n"]}]},{"cell_type":"code","source":["%ls\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EVbV6X2hXxj-","executionInfo":{"status":"ok","timestamp":1654329433441,"user_tz":-120,"elapsed":305,"user":{"displayName":"Claudia Lucio Sarsa","userId":"01191692291477770252"}},"outputId":"584c634b-3642-4029-8eb0-a757e1612b7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mCLIP\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34msteps\u001b[0m/  \u001b[01;34mtaming-transformers\u001b[0m/\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"cehKYM7liOCW"},"execution_count":null,"outputs":[]}]}