{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IDENTIFICADOR DE PATOLOGÍAS SÍSMICAS EN EDIFICIOS DE MAMPOSTERIA Y ESTRUCTURAS PORTICADAS DE HORMIGÓN ARMADO**\n",
        "\n",
        "\n",
        "El objetivo de este proyecto es el de crear un identificador preliminar de patologías edificatorias especializado en sismos.\n",
        "\n",
        "Éste se centrará en las patologías propias de estructuras de mampostería y estructuras porticadas de hormigón armado por ser éstas algunas de las estructuras más comunes en lugares gravemente afectados por actividad sísmica.\n",
        "\n",
        "Pretendemos que esta herramienta sirva de apoyo a las personas afectadas por terremotos así como a los profesionales que deberán evaluar el estado de los inmuebles después de dichas catástrofes naturales, pudiendo los últimos disponer así de un apoyo para un rápido diagnóstico. Esperamos que así se pueda agilizar la toma de medidas de seguridad.\n",
        "\n",
        "Planteamos también en un futuro la posibilidad de trabajar con los datos de las fotografías de usuarios, obteniendo las coordenadas de la fotografía para poder obtener una ubicación de los datos y entender, en caso de sismo, qué zonas han sido más afectadas y necesitan ser priorizadas.\n",
        "\n",
        "Las patologías con las que se ha entrenado este modelo son las siguientes:\n",
        "\n",
        "\n",
        "1.  Colapso. Los tipos de colapso más frecuentes que nos encontraremos en esta categoría son:\n",
        "  - Colapso total\n",
        "  - Soft story: Falla el piso más débil, muchas veces la planta baja.\n",
        "  - Pancake: Los suelos colapsan unos sobre otros de manera progresiva.\n",
        "\n",
        "2.  OOP/Partial collapse (Masonry) : Causado por las fuerzas horizontales perpendiculares al muro.\n",
        "  - Return wall separation: Separación de un muro de fachada\n",
        "  - Gable and partial facade collapse: Desplome parcial de elementos de la fachada.\n",
        "  - Out of plane due to thrust action of horizontal structure (beams).\n",
        "\n",
        "3.  IP/Partial collapse (Masonry): Causado por las fuerzas horizontales paralelas al muro.\n",
        "  - Flexural cracking\n",
        "  - Diagonal cracking\n",
        "  - Bed joint sliding\n",
        "\n",
        "4.  Combined IP/OOP and corners (Masonry): Habitualmente las fuerzas se producen en más de una dirección, causando colapsos OOP de elementos que previamente habían sufrido daños IP, o en las esquinas, que son los elementos más frágiles de las construcciones.\n",
        "\n",
        "5.  RC ST failure (RC): Fallos que ponen en riesgo la capacidad portante de la estructura porticada de hormigón armado.\n",
        "  - Shear failure of columns\n",
        "  - Loss of reinforcement\n",
        "  - Bending or reinforcement\n",
        "  \n",
        "6.  Spalling (RC): Pérdida de la capa de recubrimiendo del armado del hormigón o grietas en el mismo. No necesariamente son indicativas de daño estructural y son más fácilmente reparables que las anteriores, aunque deben ser revisadas con cuidado.\n",
        "   - Spalling\n",
        "   - Delamination\n",
        "\n",
        "7.  Infill damage (RC): Daños en los muros de relleno de una estructura porticada. Habitualmente se verán como la separación del muro de los elementos estructurales. Es posible que la estructura no se vea dañada y no presente riesgo inminente de colapso estructural. Sin embargo deben de ser tratados con cuidado dado que el peligro que representan es el desprendimiento total o parcial del muro no estructural, cuya caída es en sí misma un riesgo.\n",
        "  - OOP damage to infill in concrete structures\n",
        "  - IP damage to infill in concrete structures\n",
        "\n",
        "8.  Pounding/Leaning: Daños ocasionados por los movimientos horizontales de un edificio al inclinarse o apoyarse sobre otro.\n",
        "\n",
        "9.\tToe crushing: falla en la construcción de un muro o columna en el cual los el inferior se agrieta o desmorona.\n",
        "\n",
        "10.\tDislodgements: Desprendimiento de elementos de acabado.\n",
        "  - Tiles\n",
        "  - Bricks in facade\n",
        "  - Ceiling panels\n",
        "\n",
        "11.\tHealthy: Edificios sin patologías evidentes.\n",
        "\n"
      ],
      "metadata": {
        "id": "iZTjRNd92pj2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pHPjJ8jQ1cx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling, RandomFlip, RandomRotation, RandomZoom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqQa9dtVv36p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d5d368-3d07-44ac-f7d4-1a4afd8032b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_RiMyVbQ8OV"
      },
      "outputs": [],
      "source": [
        "train_img_Path = '/content/drive/MyDrive/Patologías Edificatorias/TEST_TRAIN_SPLIT/TRAIN'\n",
        "test_img_Path= '/content/drive/MyDrive/Patologías Edificatorias/TEST_TRAIN_SPLIT/TEST'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVglFidPp4UI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image, ImageEnhance\n",
        "\n",
        "#Vamos a crear una función que recorte nuestras imagenes como un cuadrado\n",
        "\n",
        "def recortar_imagen(imagen):\n",
        "    alto, ancho = tf.shape(imagen)[0], tf.shape(imagen)[1]\n",
        "    lado_mas_corto = tf.minimum(alto, ancho)\n",
        "\n",
        "    # Calcular las coordenadas de recorte para centrar la imagen\n",
        "    inicio_y = (alto - lado_mas_corto) // 2\n",
        "    inicio_x = (ancho - lado_mas_corto) // 2\n",
        "\n",
        "    # Recortar la imagen\n",
        "    imagen_recortada = tf.image.crop_to_bounding_box(imagen, inicio_y, inicio_x, lado_mas_corto, lado_mas_corto)\n",
        "\n",
        "    # Redimensionar la imagen al nuevo tamaño\n",
        "    imagen_recortada = tf.image.resize(imagen_recortada, (224, 224))\n",
        "\n",
        "    return imagen_recortada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQlG0jIRtTUm"
      },
      "outputs": [],
      "source": [
        "#vamos a normalizar los datos de nuestras imágenes. Cada canal toma un valor del 0 al 255, por lo qoue para escalar habremos de dividir por ese valor.\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=recortar_imagen,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IizBBDmWr5Ud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8000bffa-0fe2-4bb1-9347-8d373e29b289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7275 images belonging to 11 classes.\n"
          ]
        }
      ],
      "source": [
        "#Creamos un flujo de datos de las imagenes recortadas segun el datagen anterior, manteniendo la estructura de carpetas (etiquetas)\n",
        "\n",
        "data_generator = datagen.flow_from_directory(\n",
        "    train_img_Path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZTzwwuqTIoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7984c75-b25e-4c74-89a0-5d79fed256fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7275 files belonging to 11 classes.\n",
            "Using 5457 files for training.\n",
            "Found 1803 files belonging to 11 classes.\n",
            "Using 450 files for validation.\n"
          ]
        }
      ],
      "source": [
        "#hemos escogido un batch size de 50 ya que nuestro dataset no es demasiado grande. El tamaño de nuestras imagenes es de 224. Con este tamaño de imagen fue entrenada la red ResNet50 que hemos elegido para nuestro modelo.\n",
        "\n",
        "image_size = (224, 224)\n",
        "batch_size = 50\n",
        "\n",
        "# A continuación creamos un dataset para entrenamiento y otro para validación usando keras\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "   train_img_Path,\n",
        "   seed=123,\n",
        "   validation_split=0.25,\n",
        "   subset=\"training\",\n",
        "   image_size=image_size,\n",
        "   batch_size=batch_size\n",
        ")\n",
        "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "   test_img_Path,\n",
        "   seed=123,\n",
        "   validation_split=0.25,\n",
        "   subset=\"validation\",\n",
        "   image_size=image_size,\n",
        "   batch_size=batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP028eXETNuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eaeebc2-9dff-4a5d-9cc2-69ee4e4b424c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['01_COLLAPSE', '02_OOP_PARTIAL COLLAPSE', '03_IP_PARTIAL COLLAPSE', '04_COMBINED_CORNERS', '05_RC ST FAILURE', '06_SPALLING', '07_DAMAGE TO INFILL', '08_POUNDING_LEANING', '09_TOE CRUSHING', '10_DISLODGEMENTS', '11_HEALTHY']\n",
            "['01_COLLAPSE', '02_OOP_PARTIAL COLLAPSE', '03_IP_PARTIAL COLLAPSE', '04_COMBINED_CORNERS', '05_RC ST FAILURE', '06_SPALLING', '07_DAMAGE TO INFILL', '08_POUNDING_LEANING', '09_TOE CRUSHING', '10_DISLODGEMENTS', '11_HEALTHY']\n"
          ]
        }
      ],
      "source": [
        "#Hacemos una comprobación de que todas las clases han sido leídas correctamente\n",
        "\n",
        "print(train_ds.class_names)\n",
        "print(validation_ds.class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YhxeqxXTShE"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías de keras\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.layers.experimental import preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos el modelo preentrenado. Hemos elegido ResNet50, una red con 50 capas de profundidad entrenada con objetos genéricos.\n",
        "\n",
        "imported_model = tf.keras.applications.ResNet50(\n",
        "    # Nos aseguramos de poder incluir capas de keras para nuestro input y output.\n",
        "    include_top=False,\n",
        "    # Especificamos las dimensiones del input y los canales, que serán 3 (RGB)\n",
        "    input_shape=(224,224,3),\n",
        "    pooling=None, # Para que devuelva 4D\n",
        "    # Utilizaremos los pesos disponibles en imagenet.\n",
        "    weights='imagenet'\n",
        "    )\n",
        "\n",
        "for layer in imported_model.layers:\n",
        "  # Nos aseguramos de que los parámetros y pesos no se sometan a un nuevo entrenamiento, así aceleramos el proceso de aprendizaje.\n",
        "  layer.trainable=False"
      ],
      "metadata": {
        "id": "_cxoG-UEUaKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializamos un modelo secuencial para acceder a ResNet50\n",
        "dnn_model = Sequential()"
      ],
      "metadata": {
        "id": "L-1EL8JFUjPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importamos los comandos específicos que usaremos para crear nuestra red neuronal convolucional y para tratar de mitigar el overfitting.\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Añadimos ResNet50 como primera capa de nuestro modelo.\n",
        "dnn_model.add(imported_model)\n",
        "\n",
        "# Añadimos nuestras propias capas con regularizacion L2, Dropout y BatchNormalization para tratar de evitar overfitting.\n",
        "\n",
        "dnn_model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "dnn_model.add(MaxPooling2D((2, 2)))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.3))\n",
        "\n",
        "dnn_model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "dnn_model.add(MaxPooling2D((2, 2)))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.3))\n",
        "\n",
        "dnn_model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "# dnn_model.add(MaxPooling2D((2, 2)))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.4))\n",
        "\n",
        "dnn_model.add(Flatten())\n",
        "dnn_model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "dnn_model.add(Dropout(0.5))\n",
        "\n",
        "dnn_model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "dnn_model.add(Dropout(0.5))\n",
        "\n",
        "# Añadimos finalmente una capa densa con función de activación softmax. Esta capa tendrá tantas neuronas como categorías queramos identificar (11 en nuestro caso)\n",
        "dnn_model.add(Dense(11, activation='softmax'))"
      ],
      "metadata": {
        "id": "PdJmLiosUj8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo con un optiizador adam\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    name='adam',\n",
        ")\n",
        "\n",
        "dnn_model.compile(\n",
        "    optimizer= opt,\n",
        "    # Utilizamos las pérdidas para calcular los errores del modelo.\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    # Añadimos métricas para calcular el desempeño de nuestro modelo\n",
        "    metrics=['accuracy']\n",
        "    )"
      ],
      "metadata": {
        "id": "JCFj0aYeUmbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7CnfBQiJA1Q"
      },
      "outputs": [],
      "source": [
        "#Vamos a crear un earlystopping. Para ello vamos a monitorear el las pérdidas de nuestro set de validación, de tal manera que si no mejora en X epocas, nuestro modelo dejará de entrenarse para evitar el overfitting.\n",
        "#Pare donde pare, se quedará con los mejores datos obtenidos para val_loss.\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos nuestro modelo con los datasets que creamos para entrenamiento y validación.\n",
        "\n",
        "history = dnn_model.fit(\n",
        "train_ds,\n",
        "validation_data=validation_ds,\n",
        "epochs=25,\n",
        "callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "jvIcHV9HUrkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6867b59-1c08-482a-aca1-d27cddf754bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "110/110 [==============================] - 1516s 14s/step - loss: 2.7515 - accuracy: 0.1209 - val_loss: 2.4188 - val_accuracy: 0.2111\n",
            "Epoch 2/25\n",
            "110/110 [==============================] - 1415s 13s/step - loss: 2.3520 - accuracy: 0.2021 - val_loss: 2.1216 - val_accuracy: 0.3356\n",
            "Epoch 3/25\n",
            "110/110 [==============================] - 1419s 13s/step - loss: 2.1090 - accuracy: 0.2795 - val_loss: 1.8208 - val_accuracy: 0.4267\n",
            "Epoch 4/25\n",
            " 61/110 [===============>..............] - ETA: 9:52 - loss: 1.9220 - accuracy: 0.3416 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mWaarXRyEeV"
      },
      "outputs": [],
      "source": [
        "# Vamos a ver las gráficas de nuestro modelo.\n",
        "\n",
        "# Obtenemos los valores de pérdida y precisión del entrenamiento\n",
        "import matplotlib.pyplot as plt\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Crear una figura\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Subplot para la pérdida\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.epoch, train_loss, label='Training Loss')\n",
        "plt.plot(history.epoch, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "# Subplot para la precisión\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.epoch, train_accuracy, label='Training Accuracy')\n",
        "plt.plot(history.epoch, val_accuracy, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# Mostrar la figura\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "#Vamos a hacer alguna prueba con nuestras propias imágenes.\n",
        "\n",
        "# Ruta a la imagen que quieres probar\n",
        "image_path = '/content/drive/MyDrive/SATURDAYS AI/DATA/MY_VAL/RC.jpg'\n",
        "\n",
        "# Cargamos y preprocesamos la imagen\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Añadir una dimensión para el batch (4D)\n",
        "\n",
        "# Visualizamos la imagen de entrada\n",
        "plt.imshow(img_array[0]/255) #Normalización\n",
        "plt.title('Imagen de entrada')\n",
        "plt.axis('on')\n",
        "plt.show()\n",
        "\n",
        "# Hacemos la predicción\n",
        "predictions = dnn_model.predict(img_array)\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Mapeamos el índice de clase a la etiqueta obtenida\n",
        "class_names = ['01_COLLAPSE', '02_OOP_PARTIAL COLLAPSE', '03_IP_PARTIAL COLLAPSE', '04_COMBINED_CORNERS', '05_RC ST FAILURE', '06_SPALLING', '07_DAMAGE TO INFILL', '08_POUNDING_LEANING', '09_TOE CRUSHING', '10_DISLODGEMENTS', '11_HEALTHY']  # Asegúrate de que las etiquetas están en el orden correcto\n",
        "predicted_label = class_names[predicted_class[0]]\n",
        "\n",
        "# Imprimimos todas las probabilidades\n",
        "print(\"Probabilidades de cada clase:\")\n",
        "for i, prob in enumerate(predictions[0]):\n",
        "    print(f'{class_names[i]}: {prob:.4f}')\n",
        "\n",
        "print(f'Predicción: {predicted_label}')"
      ],
      "metadata": {
        "id": "6fkgQVfQfMMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vamos a proceder a la exportación del modelo y los pesos para nuestra API.\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "dir = '/content/drive/MyDrive/SATURDAYS AI/DATA/MODELO4'\n",
        "\n",
        "if not os.path.exists(dir):\n",
        "  os.mkdir(dir)\n",
        "\n",
        "dnn_model.save('/content/drive/MyDrive/SATURDAYS AI/DATA/MODELO4/modelo.h5')\n",
        "dnn_model.save_weights('/content/drive/MyDrive/SATURDAYS AI/DATA/MODELO4/pesos.h5')"
      ],
      "metadata": {
        "id": "mre-qiGWqh1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the history to a file (e.g., using pickle)\n",
        "import pickle\n",
        "history_path='/content/drive/MyDrive/SATURDAYS AI/DATA/MODELO4/model_history.pkl'\n",
        "\n",
        "with open(history_path, 'wb') as file:\n",
        "    pickle.dump(history.history, file)"
      ],
      "metadata": {
        "id": "2boQ3XG8co63"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}