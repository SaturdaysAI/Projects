{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0303a9d04549ebadcdbafd765941b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'no_repeat_ngram_size': 3}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3487.3333, 'train_samples_per_second': 0.113, 'train_steps_per_second': 0.057, 'train_loss': 0.30971344071205215, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, Trainer, TrainingArguments\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Cargar el CSV\n",
    "csv_file = r'data\\output\\divide_images_train\\finetuning.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Eliminar filas donde el texto está vacío\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "# Definir el procesador y el modelo preentrenado\n",
    "processor = TrOCRProcessor.from_pretrained('qantev/trocr-large-spanish')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('qantev/trocr-large-spanish')\n",
    "\n",
    "# Configurar los datos de entrenamiento\n",
    "train_texts = df['text'].tolist()  # Usamos 'text' como la descripción del texto en el CSV\n",
    "train_images = df['image_dir'].tolist()  # Usamos 'image_dir' como la ruta a las imágenes en el CSV\n",
    "\n",
    "# Definir el Dataset personalizado\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, texts, processor):\n",
    "        self.image_paths = image_paths\n",
    "        self.texts = texts\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        text = self.texts[idx]\n",
    "        \n",
    "        # Abrir la imagen con PIL\n",
    "        with Image.open(image_path) as image:\n",
    "            # Convertir la imagen a un numpy array y luego a tensor\n",
    "            image_array = np.array(image)\n",
    "            # Procesar la imagen con el TrOCRProcessor\n",
    "            processed_input = self.processor(images=image_array, return_tensors=\"pt\")\n",
    "            pixel_values = processed_input['pixel_values'].squeeze()  # Quitar dimensión extra\n",
    "\n",
    "        target = self.processor(text=text, return_tensors=\"pt\", padding=\"max_length\", truncation=True).input_ids.squeeze()\n",
    "        \n",
    "        return {'pixel_values': pixel_values, 'labels': target}\n",
    "\n",
    "# Crear el dataset personalizado\n",
    "train_dataset = CustomDataset(train_images, train_texts, processor)\n",
    "\n",
    "# Definir los argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',  # Especificar el directorio de salida\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=500,\n",
    ")\n",
    "\n",
    "# Inicializar el Trainer para el fine-tuning\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=processor,\n",
    ")\n",
    "\n",
    "# Fine-tuning del modelo\n",
    "trainer.train()\n",
    "\n",
    "# Guardar el modelo finetuneado y el procesador\n",
    "trainer.save_model(r'models\\modelo_finetuneado_trOCR')\n",
    "processor.save_pretrained(r'models\\procesador_finetuneado_trOCR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Borrar el directorio 'microsoft/trocr-base-handwritten'\n",
    "shutil.rmtree('microsoft/trocr-base-handwritten')\n",
    "\n",
    "print(\"Eliminado el directorio 'microsoft/trocr-base-handwritten' después de completar el proceso.\")\n",
    "\n",
    "# Ruta donde se almacena la caché (reemplaza 'ruta_de_la_cache' con la ruta real)\n",
    "#Daniel cache_path = r'C:\\Users\\Jack\\.cache\\huggingface\\hub\\models--microsoft--trocr-large-handwritten'\n",
    "#Carlos\n",
    "cache_path = r'C:\\Users\\carlo\\.cache\\huggingface\\hub\\models--microsoft--trocr-large-handwritten'\n",
    "\n",
    "# Verificar si la ruta existe y es un directorio\n",
    "if os.path.exists(cache_path) and os.path.isdir(cache_path):\n",
    "    # Borrar todos los archivos y subdirectorios dentro de la caché\n",
    "    shutil.rmtree(cache_path)\n",
    "    print(f\"Caché en {cache_path} borrada correctamente.\")\n",
    "else:\n",
    "    print(f\"No se encontró la caché en {cache_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SATURDAYS-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
