{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mB-O_VvhJXQ"
   },
   "source": [
    "# **Facial Expressions Saturdays Ai**\n",
    "\n",
    "Proyecto de la primera edición de Donostia de Saturdays Ai 2020.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\alumno\\appdata\\roaming\\python\\python37\\site-packages (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "!pip3 install --user --upgrade numpy\n",
    "!pip3 install --ignore-installed --upgrade TensorFlow\n",
    "!pip3 install --user --upgrade pandas\n",
    "!pip uninstall tensorflow tensorflow-tensorboard tensorflow-estimator --yes\n",
    "!pip3 install tensorflow\n",
    "!pip3 install keras\n",
    "!pip3 install --user --upgrade tensorflow-gpu\n",
    "!pip3 install --user --upgrade tensorboard\n",
    "!pip3 install keras==2.3.1\n",
    "!pip3 install --user --upgrade tensorflow-gpu==1.14.0\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Importación data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for i in os.listdir('data/train/0'):\n",
    "    labels.append(0)\n",
    "for i in os.listdir('data/train/1'):\n",
    "    labels.append(1)\n",
    "for i in os.listdir('data/train/2'):\n",
    "    labels.append(2)\n",
    "for i in os.listdir('data/train/3'):\n",
    "    labels.append(3)\n",
    "for i in os.listdir('data/train/4'):\n",
    "    labels.append(4)\n",
    "for i in os.listdir('data/train/5'):\n",
    "    labels.append(5)\n",
    "for i in os.listdir('data/train/6'):\n",
    "    labels.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction on training data\n",
    "\n",
    "loc1 = 'data/train/0'\n",
    "loc2 = 'data/train/1'\n",
    "loc3 = 'data/train/2'\n",
    "loc4 = 'data/train/3'\n",
    "loc5 = 'data/train/4'\n",
    "loc6 = 'data/train/5'\n",
    "loc7 = 'data/train/6'\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in tqdm(os.listdir(loc1)):\n",
    "    features.append(cv2.imread(os.path.join(loc1,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc2)):\n",
    "    features.append(cv2.imread(os.path.join(loc2,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc3)):\n",
    "    features.append(cv2.imread(os.path.join(loc3,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc4)):\n",
    "    features.append(cv2.imread(os.path.join(loc4,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc5)):\n",
    "    features.append(cv2.imread(os.path.join(loc5,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc6)):\n",
    "    features.append(cv2.imread(os.path.join(loc6,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc7)):\n",
    "    features.append(cv2.imread(os.path.join(loc7,i),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = []\n",
    "for i in os.listdir('data/test/0'):\n",
    "    labels_test.append(0)\n",
    "for i in os.listdir('data/test/1'):\n",
    "    labels_test.append(1)\n",
    "for i in os.listdir('data/test/2'):\n",
    "    labels_test.append(2)\n",
    "for i in os.listdir('data/test/3'):\n",
    "    labels_test.append(3)\n",
    "for i in os.listdir('data/test/4'):\n",
    "    labels_test.append(4)\n",
    "for i in os.listdir('data/test/5'):\n",
    "    labels_test.append(5)\n",
    "for i in os.listdir('data/test/6'):\n",
    "    labels_test.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction on testing data\n",
    "\n",
    "loc1 = 'data/test/0'\n",
    "loc2 = 'data/test/1'\n",
    "loc3 = 'data/test/2'\n",
    "loc4 = 'data/test/3'\n",
    "loc5 = 'data/test/4'\n",
    "loc6 = 'data/test/5'\n",
    "loc7 = 'data/test/6'\n",
    "\n",
    "test_features = []\n",
    "\n",
    "for i in tqdm(os.listdir(loc1)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc1,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc2)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc2,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc3)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc3,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc4)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc4,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc5)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc5,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc6)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc6,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc7)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc7,i),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['emotion'] = labels\n",
    "train_data['pixel_values'] = features\n",
    "test_data['emotion'] = labels_test\n",
    "test_data['pixel_values'] = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "def setup_axe(axe,df,title):\n",
    "    df['emotion'].value_counts(sort=False).plot(ax=axe, kind='bar', rot=0)\n",
    "    axe.set_xticklabels(emotion_labels)\n",
    "    axe.set_xlabel(\"Emotions\")\n",
    "    axe.set_ylabel(\"Count\")\n",
    "    axe.set_title(title)\n",
    "    \n",
    "    # set individual bar lables using above list\n",
    "    for i in axe.patches:\n",
    "         axe.text(i.get_x()-.05, i.get_height()+120, \\\n",
    "                str(round((i.get_height()), 2)), fontsize=14, color='red',\n",
    "                    rotation=0)\n",
    "\n",
    "import matplotlib.pyplot as plt   \n",
    "fig, axes = plt.subplots(1,2, figsize=(20,8), sharey=True)\n",
    "setup_axe(axes[0],train_data,'train')\n",
    "setup_axe(axes[1],test_data,'test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features).reshape(-1,48,48,1)\n",
    "test_features = np.array(test_features).reshape(-1,48,48,1)\n",
    "\n",
    "features = features/255\n",
    "test_features = test_features/255\n",
    "\n",
    "labels = np_utils.to_categorical(labels)\n",
    "labels_test =np_utils.to_categorical(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training features shape ',features.shape)\n",
    "print('Training labels shape',labels.shape)\n",
    "print('Testing features shape ',test_features.shape)\n",
    "print('Testing labels shape',labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, Conv2D, BatchNormalization,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape = (48,48,1)\n",
    "model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "  \n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', patience = 10, mode = 'min', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=features, \n",
    "            y=labels,\n",
    "            epochs=10, \n",
    "            steps_per_epoch = len(features)/64,\n",
    "            verbose=1, \n",
    "            callbacks = [es],\n",
    "            validation_data=(test_features,labels_test),  \n",
    "            validation_steps = len(test_features)/64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib \n",
    "joblib.dump(history, 'modelo_entrenado.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true = np.argmax(labels_test, axis=1)\n",
    "test_pred = np.argmax(model.predict(test_features), axis=1)\n",
    "print(\"CNN Model Accuracy on testing data: {:.4f}\".format(accuracy_score(test_true, test_pred)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AISaturdays_ChallengeSession5.ipynb",
   "provenance": [
    {
     "file_id": "1eDULJv1udQFKK4WLY0M_f9jBxibhzmXs",
     "timestamp": 1583527306059
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
