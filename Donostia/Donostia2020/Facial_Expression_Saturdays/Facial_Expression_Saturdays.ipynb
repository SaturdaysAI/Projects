{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mB-O_VvhJXQ"
   },
   "source": [
    "# **Facial Expressions Saturdays Ai**\n",
    "\n",
    "Proyecto de la primera edición de Donostia de Saturdays Ai 2020.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Importación data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for i in os.listdir('data/train/0'):\n",
    "    labels.append(0)\n",
    "for i in os.listdir('data/train/1'):\n",
    "    labels.append(1)\n",
    "for i in os.listdir('data/train/2'):\n",
    "    labels.append(2)\n",
    "for i in os.listdir('data/train/3'):\n",
    "    labels.append(3)\n",
    "for i in os.listdir('data/train/4'):\n",
    "    labels.append(4)\n",
    "for i in os.listdir('data/train/5'):\n",
    "    labels.append(5)\n",
    "for i in os.listdir('data/train/6'):\n",
    "    labels.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3995/3995 [00:00<00:00, 9271.90it/s]\n",
      "100%|██████████| 436/436 [00:00<00:00, 9277.93it/s]\n",
      "100%|██████████| 4097/4097 [00:00<00:00, 9309.38it/s]\n",
      "100%|██████████| 7215/7215 [00:00<00:00, 9250.53it/s]\n",
      "100%|██████████| 4830/4830 [00:00<00:00, 8982.27it/s]\n",
      "100%|██████████| 3171/3171 [00:00<00:00, 9341.47it/s]\n",
      "100%|██████████| 4965/4965 [00:00<00:00, 9099.64it/s]\n"
     ]
    }
   ],
   "source": [
    "#feature extraction on training data\n",
    "\n",
    "loc1 = 'data/train/0'\n",
    "loc2 = 'data/train/1'\n",
    "loc3 = 'data/train/2'\n",
    "loc4 = 'data/train/3'\n",
    "loc5 = 'data/train/4'\n",
    "loc6 = 'data/train/5'\n",
    "loc7 = 'data/train/6'\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in tqdm(os.listdir(loc1)):\n",
    "    features.append(cv2.imread(os.path.join(loc1,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc2)):\n",
    "    features.append(cv2.imread(os.path.join(loc2,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc3)):\n",
    "    features.append(cv2.imread(os.path.join(loc3,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc4)):\n",
    "    features.append(cv2.imread(os.path.join(loc4,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc5)):\n",
    "    features.append(cv2.imread(os.path.join(loc5,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc6)):\n",
    "    features.append(cv2.imread(os.path.join(loc6,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc7)):\n",
    "    features.append(cv2.imread(os.path.join(loc7,i),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = []\n",
    "for i in os.listdir('data/test/0'):\n",
    "    labels_test.append(0)\n",
    "for i in os.listdir('data/test/1'):\n",
    "    labels_test.append(1)\n",
    "for i in os.listdir('data/test/2'):\n",
    "    labels_test.append(2)\n",
    "for i in os.listdir('data/test/3'):\n",
    "    labels_test.append(3)\n",
    "for i in os.listdir('data/test/4'):\n",
    "    labels_test.append(4)\n",
    "for i in os.listdir('data/test/5'):\n",
    "    labels_test.append(5)\n",
    "for i in os.listdir('data/test/6'):\n",
    "    labels_test.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 491/491 [00:00<00:00, 9443.47it/s]\n",
      "100%|██████████| 55/55 [00:00<00:00, 7532.38it/s]\n",
      "100%|██████████| 528/528 [00:00<00:00, 9167.80it/s]\n",
      "100%|██████████| 879/879 [00:00<00:00, 9403.38it/s]\n",
      "100%|██████████| 594/594 [00:00<00:00, 9303.66it/s]\n",
      "100%|██████████| 416/416 [00:00<00:00, 9273.27it/s]\n",
      "100%|██████████| 626/626 [00:00<00:00, 9147.50it/s]\n"
     ]
    }
   ],
   "source": [
    "#feature extraction on testing data\n",
    "\n",
    "loc1 = 'data/test/0'\n",
    "loc2 = 'data/test/1'\n",
    "loc3 = 'data/test/2'\n",
    "loc4 = 'data/test/3'\n",
    "loc5 = 'data/test/4'\n",
    "loc6 = 'data/test/5'\n",
    "loc7 = 'data/test/6'\n",
    "\n",
    "test_features = []\n",
    "\n",
    "for i in tqdm(os.listdir(loc1)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc1,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc2)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc2,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc3)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc3,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc4)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc4,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc5)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc5,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc6)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc6,i),0))\n",
    "    \n",
    "for i in tqdm(os.listdir(loc7)):\n",
    "    test_features.append(cv2.imread(os.path.join(loc7,i),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['emotion'] = labels\n",
    "train_data['pixel_values'] = features\n",
    "test_data['emotion'] = labels_test\n",
    "test_data['pixel_values'] = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixel_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 3, 11, 36, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[90, 117, 158, 162, 157, 156, 164, 168, 171, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[[9, 9, 12, 23, 41, 67, 96, 118, 128, 139, 147...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[[35, 37, 41, 37, 26, 85, 134, 125, 158, 184, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 254,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                       pixel_values\n",
       "0        0  [[0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 3, 11, 36, ...\n",
       "1        0  [[90, 117, 158, 162, 157, 156, 164, 168, 171, ...\n",
       "2        0  [[9, 9, 12, 23, 41, 67, 96, 118, 128, 139, 147...\n",
       "3        0  [[35, 37, 41, 37, 26, 85, 134, 125, 158, 184, ...\n",
       "4        0  [[255, 255, 255, 255, 255, 255, 255, 255, 254,..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "def setup_axe(axe,df,title):\n",
    "    df['emotion'].value_counts(sort=False).plot(ax=axe, kind='bar', rot=0)\n",
    "    axe.set_xticklabels(emotion_labels)\n",
    "    axe.set_xlabel(\"Emotions\")\n",
    "    axe.set_ylabel(\"Count\")\n",
    "    axe.set_title(title)\n",
    "    \n",
    "    # set individual bar lables using above list\n",
    "    for i in axe.patches:\n",
    "         axe.text(i.get_x()-.05, i.get_height()+120, \\\n",
    "                str(round((i.get_height()), 2)), fontsize=14, color='red',\n",
    "                    rotation=0)\n",
    "\n",
    "import matplotlib.pyplot as plt   \n",
    "fig, axes = plt.subplots(1,2, figsize=(20,8), sharey=True)\n",
    "setup_axe(axes[0],train_data,'train')\n",
    "setup_axe(axes[1],test_data,'test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features).reshape(-1,48,48,1)\n",
    "test_features = np.array(test_features).reshape(-1,48,48,1)\n",
    "\n",
    "features = features/255\n",
    "test_features = test_features/255\n",
    "\n",
    "labels = np_utils.to_categorical(labels)\n",
    "labels_test =np_utils.to_categorical(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape  (28709, 48, 48, 1)\n",
      "Training labels shape (28709, 7)\n",
      "Testing features shape  (3589, 48, 48, 1)\n",
      "Testing labels shape (3589, 7)\n"
     ]
    }
   ],
   "source": [
    "print('Training features shape ',features.shape)\n",
    "print('Training labels shape',labels.shape)\n",
    "print('Testing features shape ',test_features.shape)\n",
    "print('Testing labels shape',labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, Conv2D, BatchNormalization,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    input_shape = (48,48,1)\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 2,787,015\n",
      "Trainable params: 2,785,863\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 \n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "448/448 [==============================] - 1680s 4s/step - loss: 1.8558 - accuracy: 0.2823 - val_loss: 1.4940 - val_accuracy: 0.4232\n",
      "\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "Epoch 2/10\n",
      "  3/448 [..............................] - ETA: 26:45 - loss: 1.3290 - accuracy: 0.4965"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-537afe5810c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             validation_steps = len(test_features)/64)\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/Facial_Expression_Saturdays/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/Facial_Expression_Saturdays/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/Facial_Expression_Saturdays/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/Facial_Expression_Saturdays/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/Facial_Expression_Saturdays/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/Facial_Expression_Saturdays/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/SageMaker/Facial_Expression_Saturdays/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=features, \n",
    "            y=labels,\n",
    "            epochs=10, \n",
    "            steps_per_epoch = len(features)/64,\n",
    "            verbose=1, \n",
    "            callbacks = [cp_callback],\n",
    "            validation_data=(test_features,labels_test),  \n",
    "            validation_steps = len(test_features)/64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f801fb2b7f0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "448/448 [==============================] - 1660s 4s/step - loss: 1.3015 - accuracy: 0.5008 - val_loss: 1.3649 - val_accuracy: 0.4756\n",
      "\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "Epoch 2/10\n",
      "448/448 [==============================] - 2488s 6s/step - loss: 1.1186 - accuracy: 0.5785 - val_loss: 1.2394 - val_accuracy: 0.5202\n",
      "\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "Epoch 3/10\n",
      "448/448 [==============================] - 6085s 14s/step - loss: 1.0066 - accuracy: 0.6275 - val_loss: 1.2103 - val_accuracy: 0.5403\n",
      "\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "Epoch 4/10\n",
      "448/448 [==============================] - 6210s 14s/step - loss: 0.8947 - accuracy: 0.6660 - val_loss: 1.3548 - val_accuracy: 0.5302\n",
      "\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "Epoch 5/10\n",
      "268/448 [================>.............] - ETA: 39:50 - loss: 0.7282 - accuracy: 0.7332"
     ]
    }
   ],
   "source": [
    "model.fit(x=features, \n",
    "            y=labels,\n",
    "            epochs=10, \n",
    "            steps_per_epoch = len(features)/64,\n",
    "            verbose=1, \n",
    "            callbacks = [cp_callback],\n",
    "            validation_data=(test_features,labels_test),  \n",
    "            validation_steps = len(test_features)/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7feb9afd9d30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 6070s 14s/step - loss: 0.1220 - accuracy: 0.9602 - val_loss: 1.8791 - val_accuracy: 0.6035\n",
      "\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feb99704470>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=features, \n",
    "            y=labels,\n",
    "            epochs=1, \n",
    "            steps_per_epoch = len(features)/64,\n",
    "            verbose=1, \n",
    "            callbacks = [cp_callback],\n",
    "            validation_data=(test_features,labels_test),  \n",
    "            validation_steps = len(test_features)/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib \n",
    "joblib.dump(model, 'modelo_entrenado.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 45s - loss: 1.8791 - accuracy: 0.6035\n",
      "Restored model, accuracy: 60.35%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_features, labels_test, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Model Accuracy on testing data: 0.1733\n"
     ]
    }
   ],
   "source": [
    "test_true = np.argmax(labels_test, axis=1)\n",
    "test_pred = np.argmax(model.predict(test_features), axis=1)\n",
    "print(\"CNN Model Accuracy on testing data: {:.4f}\".format(accuracy_score(test_true, test_pred)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AISaturdays_ChallengeSession5.ipynb",
   "provenance": [
    {
     "file_id": "1eDULJv1udQFKK4WLY0M_f9jBxibhzmXs",
     "timestamp": 1583527306059
    }
   ]
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
